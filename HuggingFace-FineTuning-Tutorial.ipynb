{"cells":[{"attachments":{},"cell_type":"markdown","id":"7b78cb51-e5d9-4c49-8f1a-f7f0d2c527d3","metadata":{"language":"python"},"source":"# Fine-tune a Pre-trained Model Using HuggingFace Transformers\nFine-tuning a pretrained model allows you to leverage the vast amount of knowledge encoded in the model from its initial training on large datasets. This approach significantly reduces the time and computational resources required compared to training a model from scratch. It also helps achieve high performance with relatively small amounts of task-specific data, making it a powerful technique in machine learning and AI development.\n\n## Steps for Fine-Tuning a Pretrained Model\n#### Choose a Pretrained Model: \nSelect a model from the Hugging Face Model Hub that suits your task. For example, if you're working on text classification, models like BERT or RoBERTa are popular choices.\n\n#### Prepare Your Dataset: \nEnsure your dataset is properly formatted. For text tasks, this usually involves tokenizing your text data. You can use the Tokenizer provided by the Transformers library to convert your text into input IDs and attention masks.\n\n#### Set Up Training Arguments: \nDefine your training parameters using TrainingArguments. This includes specifying the output directory, evaluation strategy, learning rate, batch size, and number of epochs.\n\n#### Create a Trainer: \nInstantiate a Trainer object, which will handle the training process. You need to provide your model, training arguments, training dataset, evaluation dataset, and a function to compute metrics.\n\n#### Train the Model: \nCall the train() method on your Trainer object to start the fine-tuning process.\n\n#### Evaluate the Model: \nAfter training, you can evaluate the model's performance on the validation dataset to check its accuracy and other metrics."},{"attachments":{},"cell_type":"markdown","id":"d1fa291d-e985-4989-a503-f5ebde0d861d","metadata":{"language":"python"},"source":"## Goal of Fine-tuning\nWe are going to train a model using the Yelp review dataset. The primary goal is to fine-tune the pretrained model so it can accurately classify the sentiment of Yelp reviews (e.g., positive or negative). "},{"attachments":{},"cell_type":"markdown","id":"3e92969f-5796-490e-9490-438ff002fe3c","metadata":{"language":"python"},"source":"### Install all the necessary libraries"},{"cell_type":"code","execution_count":10,"id":"d0c14d2d-4102-44df-b89f-24c31412d242","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:11:51.672601Z","iopub.status.busy":"2024-08-03T14:11:51.672217Z","iopub.status.idle":"2024-08-03T14:11:58.669563Z","shell.execute_reply":"2024-08-03T14:11:58.668642Z","shell.execute_reply.started":"2024-08-03T14:11:51.672572Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.36.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (2.16.1)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (0.4.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.26.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.15.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.24.5)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.10.0)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.3.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.20)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"}],"source":"!pip install transformers datasets evaluate accelerate"},{"attachments":{},"cell_type":"markdown","id":"3af7bd6a-4154-4d8f-b6dc-7bbe6ff69ff9","metadata":{"language":"python"},"source":"### You’ll also need to install your preferred machine learning framework - Pytorch or TensorFlow."},{"cell_type":"code","execution_count":11,"id":"c5fbec99-a7f8-45a6-8455-d1e4ffdf976c","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:12:10.495240Z","iopub.status.busy":"2024-08-03T14:12:10.493439Z","iopub.status.idle":"2024-08-03T14:12:16.655376Z","shell.execute_reply":"2024-08-03T14:12:16.653851Z","shell.execute_reply.started":"2024-08-03T14:12:10.495203Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.15.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch) (4.8.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.0.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch) (2.18.1)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch) (2.1.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.0.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"}],"source":"!pip install torch"},{"attachments":{},"cell_type":"markdown","id":"91e10f92-f9df-4de0-9c85-1776cacbefc6","metadata":{"language":"python"},"source":"### Begin by loading the Yelp Reviews dataset:"},{"cell_type":"code","execution_count":12,"id":"97652fb9-c986-4d28-83a7-a526c1aee46a","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:12:56.598566Z","iopub.status.busy":"2024-08-03T14:12:56.598018Z","iopub.status.idle":"2024-08-03T14:13:07.700278Z","shell.execute_reply":"2024-08-03T14:13:07.699580Z","shell.execute_reply.started":"2024-08-03T14:12:56.598526Z"},"language":"python","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77d72366ed404077a1ef59a6c12f7e9a","version_major":2,"version_minor":0},"text/plain":"Downloading readme:   0%|          | 0.00/6.72k [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33b492b59966406a82e49ed9f708c5de","version_major":2,"version_minor":0},"text/plain":"Downloading data:   0%|          | 0.00/299M [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6e980ebf8324b3d9084d4f3009ca539","version_major":2,"version_minor":0},"text/plain":"Downloading data:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f51febaee6c4482b813099f99cb9397","version_major":2,"version_minor":0},"text/plain":"Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ad298d95cbc4196845cf7d9487a69af","version_major":2,"version_minor":0},"text/plain":"Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"{'label': 0,\n 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":"from datasets import load_dataset\n\ndataset = load_dataset(\"yelp_review_full\")\ndataset[\"train\"][100]"},{"attachments":{},"cell_type":"markdown","id":"9ea8536a-2503-43df-91b5-cd5bef2c2b7f","metadata":{"language":"python"},"source":"### Tokenize the text data to prepare it for the model."},{"cell_type":"code","execution_count":13,"id":"3d4efac4-df31-4ebc-989b-441671015451","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:13:42.666380Z","iopub.status.busy":"2024-08-03T14:13:42.665822Z","iopub.status.idle":"2024-08-03T14:16:31.954914Z","shell.execute_reply":"2024-08-03T14:16:31.954223Z","shell.execute_reply.started":"2024-08-03T14:13:42.666342Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14ecbd996bc34ba195294fcbd682f50b","version_major":2,"version_minor":0},"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7f24ead471d41c2992ec970c7423818","version_major":2,"version_minor":0},"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61939677c63b4b3a8b31be31da562971","version_major":2,"version_minor":0},"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7e73f287ee34c60aa15d965a7d03a2f","version_major":2,"version_minor":0},"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1cdb71db25d746bc9026e64128eb0e16","version_major":2,"version_minor":0},"text/plain":"Map:   0%|          | 0/650000 [00:00<?, ? examples/s]"},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfcca20cc5ff450885747df6168afad5","version_major":2,"version_minor":0},"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"},"metadata":{},"output_type":"display_data"}],"source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)"},{"attachments":{},"cell_type":"markdown","id":"23205462-2b4f-473d-a59c-fc6ccf10562e","metadata":{"language":"python"},"source":"#### If you like, you can create a smaller subset of the full dataset to fine-tune on to reduce the time it takes:"},{"cell_type":"code","execution_count":18,"id":"c54ed4b9-436c-4eef-8d63-92d13227b148","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:16:46.467587Z","iopub.status.busy":"2024-08-03T14:16:46.467193Z","iopub.status.idle":"2024-08-03T14:16:46.625610Z","shell.execute_reply":"2024-08-03T14:16:46.624941Z","shell.execute_reply.started":"2024-08-03T14:16:46.467556Z"},"language":"python","trusted":true},"outputs":[],"source":"small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"},{"attachments":{},"cell_type":"markdown","id":"ebbf6a01-a836-4c45-be39-682712e7798e","metadata":{"language":"python"},"source":"#### Train with PyTorch Trainer"},{"cell_type":"code","execution_count":19,"id":"2bb7b657-227d-44ce-9aed-fd714ac556d1","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:16:59.079293Z","iopub.status.busy":"2024-08-03T14:16:59.078861Z","iopub.status.idle":"2024-08-03T14:17:01.291492Z","shell.execute_reply":"2024-08-03T14:17:01.290691Z","shell.execute_reply.started":"2024-08-03T14:16:59.079259Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8775f54e17d432196f50dd399041598","version_major":2,"version_minor":0},"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"}],"source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"},{"attachments":{},"cell_type":"markdown","id":"6efecfaf-e01c-4026-9645-a40e3a41da07","metadata":{"language":"python"},"source":"### Training hyperparameters\n\ncreate a TrainingArguments class which contains all the hyperparameters you can tune as well as flags for activating different training options. "},{"cell_type":"code","execution_count":20,"id":"fe29bb26-3bb1-40d2-a9da-1b88610d0237","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:17:17.996343Z","iopub.status.busy":"2024-08-03T14:17:17.995911Z","iopub.status.idle":"2024-08-03T14:17:18.016618Z","shell.execute_reply":"2024-08-03T14:17:18.015931Z","shell.execute_reply.started":"2024-08-03T14:17:17.996306Z"},"language":"python","trusted":true},"outputs":[],"source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\"test_trainer\")"},{"cell_type":"code","execution_count":24,"id":"885d1d55-c168-467f-b8a2-01d71120aeab","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:18:27.172274Z","iopub.status.busy":"2024-08-03T14:18:27.171711Z","iopub.status.idle":"2024-08-03T14:18:34.971800Z","shell.execute_reply":"2024-08-03T14:18:34.970377Z","shell.execute_reply.started":"2024-08-03T14:18:27.172236Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"},{"name":"stdout","output_type":"stream","text":"Collecting scikit-learn\n  Downloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.14.0)\nCollecting joblib>=1.2.0 (from scikit-learn)\n  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn)\n  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\nDownloading scikit_learn-1.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m149.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\nInstalling collected packages: threadpoolctl, joblib, scikit-learn\nSuccessfully installed joblib-1.4.2 scikit-learn-1.5.1 threadpoolctl-3.5.0\n"}],"source":"!pip install scikit-learn"},{"attachments":{},"cell_type":"markdown","id":"8341b6f0-962f-4a66-8048-f8eb9d3ee04a","metadata":{"language":"python"},"source":"#### Evaluate\nTrainer does not automatically evaluate model performance during training. You’ll need to pass Trainer a function to compute and report metrics."},{"cell_type":"code","execution_count":25,"id":"9ba2f4ca-df99-4413-9222-8d03d296fc2d","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:18:37.513836Z","iopub.status.busy":"2024-08-03T14:18:37.513144Z","iopub.status.idle":"2024-08-03T14:18:38.232456Z","shell.execute_reply":"2024-08-03T14:18:38.231790Z","shell.execute_reply.started":"2024-08-03T14:18:37.513804Z"},"language":"python","trusted":true},"outputs":[],"source":"import numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")"},{"cell_type":"code","execution_count":26,"id":"000c632c-0ef2-4247-a6eb-16050eb56214","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:18:46.312370Z","iopub.status.busy":"2024-08-03T14:18:46.305972Z","iopub.status.idle":"2024-08-03T14:18:46.317780Z","shell.execute_reply":"2024-08-03T14:18:46.317072Z","shell.execute_reply.started":"2024-08-03T14:18:46.312333Z"},"language":"python","trusted":true},"outputs":[],"source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)"},{"attachments":{},"cell_type":"markdown","id":"e7ead274-dff3-4870-a542-8a4b9ced2617","metadata":{"language":"python"},"source":"#### Trainer\nCreate a Trainer object with your model, training arguments, training and test datasets, and evaluation function."},{"cell_type":"code","execution_count":28,"id":"f41c4ee1-d179-42eb-9427-556f24b20aae","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:19:45.961376Z","iopub.status.busy":"2024-08-03T14:19:45.961007Z","iopub.status.idle":"2024-08-03T14:19:46.048358Z","shell.execute_reply":"2024-08-03T14:19:46.047715Z","shell.execute_reply.started":"2024-08-03T14:19:45.961343Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"}],"source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)"},{"attachments":{},"cell_type":"markdown","id":"ddd09d90-38cd-4b18-acec-ab64d0739c8b","metadata":{"language":"python"},"source":"#### Fine-tune your model by calling train()"},{"cell_type":"code","execution_count":30,"id":"370ba855-3d52-4015-8d34-c92ca73109c1","metadata":{"execution":{"iopub.execute_input":"2024-08-03T14:20:00.953411Z","iopub.status.busy":"2024-08-03T14:20:00.953020Z","iopub.status.idle":"2024-08-03T15:36:46.217096Z","shell.execute_reply":"2024-08-03T15:36:46.216416Z","shell.execute_reply.started":"2024-08-03T14:20:00.953376Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 1:16:33, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>","text/plain":"<IPython.core.display.HTML object>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.977566650390625, metrics={'train_runtime': 4605.0362, 'train_samples_per_second': 0.651, 'train_steps_per_second': 0.081, 'total_flos': 789354427392000.0, 'train_loss': 0.977566650390625, 'epoch': 3.0})"},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":"trainer.train()"},{"attachments":{},"cell_type":"markdown","id":"732936f8-187b-491f-86d3-24c735c693c0","metadata":{"language":"python"},"source":"#### Here's a detailed explanation of each component:\n\n##### global_step=375:\nThis indicates the total number of steps (batches) the model has been trained on. Each step corresponds to one batch of data passed through the model.\n\n##### training_loss=0.977566650390625:\nThe average training loss over all batches and epochs. Loss is a measure of how well the model is performing on the training data; a lower value indicates better performance. Here, the training loss is approximately 0.978.\n\n##### metrics:train_runtime=4605.0362: \nThe total time taken to complete the training, in seconds (approximately 4605 seconds, or about 1 hour and 17 minutes).\n\n##### train_samples_per_second=0.651: \nThe number of training samples processed per second. This value is relatively low, indicating the process might be computationally intensive or the hardware may not be optimal.\n\n##### train_steps_per_second=0.081: \nThe number of training steps (batches) processed per second.\n\n##### total_flos=789354427392000.0: \nFloating-point operations per second (FLOPs) used during training. This metric gives an indication of the computational workload.\n\n##### train_loss=0.977566650390625: \nThe same as the training loss mentioned earlier.\n\n##### epoch=3.0: \nIndicates that the training process ran for 3 epochs (full passes over the training dataset)."},{"attachments":{},"cell_type":"markdown","id":"9e1c82f0-c739-4888-9c5e-27f2685e69d5","metadata":{"language":"python"},"source":"#### Evaluate the model\nAfter training, you can evaluate the model to see its performance on the evaluation dataset."},{"cell_type":"code","execution_count":81,"id":"6cdde528-9cdd-4dce-82a5-313935a90eed","metadata":{"execution":{"iopub.execute_input":"2024-08-03T15:37:46.757270Z","iopub.status.busy":"2024-08-03T15:37:46.756826Z","iopub.status.idle":"2024-08-03T15:42:52.820237Z","shell.execute_reply":"2024-08-03T15:42:52.819454Z","shell.execute_reply.started":"2024-08-03T15:37:46.757230Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 05:03]\n    </div>\n    ","text/plain":"<IPython.core.display.HTML object>"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"{'eval_loss': 1.0017979145050049, 'eval_accuracy': 0.606, 'eval_runtime': 306.0542, 'eval_samples_per_second': 3.267, 'eval_steps_per_second': 0.408, 'epoch': 3.0}\n"}],"source":"eval_results = trainer.evaluate()\nprint(eval_results)"},{"attachments":{},"cell_type":"markdown","id":"491f3363-2747-42fd-9d1e-65859a877262","metadata":{"language":"python"},"source":"#### Here's a detailed explanation of each component:\n\n##### eval_loss=1.0017979145050049:\nThe loss computed on the evaluation (validation) dataset. Similar to training loss, it indicates how well the model is performing on unseen data. Here, the evaluation loss is approximately 1.002.\n\n##### eval_accuracy=0.606:\nThe accuracy of the model on the evaluation dataset. It represents the proportion of correctly classified instances. An accuracy of 0.606 means the model correctly classified 60.6% of the evaluation samples.\n\n##### eval_runtime=306.0542:\nThe total time taken to complete the evaluation, in seconds (approximately 306 seconds, or about 5 minutes and 6 seconds).\n\n##### eval_samples_per_second=3.267:\nThe number of evaluation samples processed per second. This value is higher than the training samples per second, which is common since evaluation usually involves forward passes only, without backpropagation.\n\n##### eval_steps_per_second=0.408:\nThe number of evaluation steps (batches) processed per second. This value is also higher than the training steps per second, for similar reasons."},{"attachments":{},"cell_type":"markdown","id":"1b7805b7-76da-46f9-a18c-4b3621d0ab3f","metadata":{"language":"python"},"source":"You successfully fine-tuned a pretrained model (e.g., BERT) on the Yelp review dataset. The model adapted its general language understanding to the specific task of sentiment analysis on Yelp reviews."}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"d82f0eed-b7ed-49ef-87f7-106f7fa21a73","defaultDatabase":"database_c229c"},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}